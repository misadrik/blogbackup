<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[多线程，多进程下微博图片]]></title>
    <url>%2F2018%2F04%2F25%2F2018-04-25-downloadpics%2F</url>
    <content type="text"><![CDATA[图片多线程多进程下载概述爬了微博后图片一直是用链接保存的，前阵子喜欢上了优子酱，喜欢着装风格，疯狂找图片，于是爬了她的粉丝微博，下了所有的图片。由于这个实现起来没有顺序，相对简单，下一步就要考虑用多线程和多进程对微博爬虫进行改造了，不过这个需要时间，等技术更加纯熟再弄可能会更好。 主要内容下载函数urlretrieve12import urllib.requesturlretrieve(url, filename=None, reporthook=None, data=None) 参数 finename 指定了保存本地路径（如果参数未指定，urllib会生成一个临时文件保存数据。） 参数reporthook是一个回调函数，当连接上服务器、以及相应的数据块传输完毕时会触发该回调，我们可以利用这个回调函数来显示当前的下载进度。 参数data指 post 到服务器的数据，该方法返回一个包含两个元素的(filename, headers)元组，filename 表示保存到本地的路径，header 表示服务器的响应头 多线程threading概念多线程是并行的一种。计算机只有一个CPU核心，同时只能处理一个任务。这样的情况下，多线程可以理解为开辟多条道路，但道路的出口只有一个。哪条路上的车抢到了通行权这条路上的汽车就会优先通过，直到下条路上的车抢到通行权，此时其他路上的汽车都会进入等待状态。使用多线程，可以大大的增加程序的性能和效率。 ###多线程的使用 在python3 中一般使用 threading 库 123import threadingt = Thread(target=function_name, args=(function_parameter1, function_parameterN)) # 启动刚刚创建的线程 t.start() 参数function_name用于指定执行多线程的函数名字（只要名字） 参数args是前述函数的参数 此函数也可通过类的继承使用 12345678910111213141516171819202122232425262728import threadingimport datetimeimport timeclass my_Thread (threading.Thread): def __init__(self, threadID, name, delay): threading.Thread.__init__(self) self.threadID = threadID self.name = name self.delay = delay def run(self): print ("开始线程：" + self.name) print_datetime(self.name, self.delay, 5) print ("退出线程：" + self.name) def print_datetime(threadName, delay, counter): while counter: time.sleep(delay) print ("%s: %s" % (threadName, datetime.datetime.now())) counter -= 1 thread1 = my_Thread(1, "Thread-1", 1)thread2 = my_Thread(2, "Thread-2", 2)thread1.start()thread2.start()thread1.join()thread2.join() 输出 123456789101112131415# 输出开始线程：Thread-1开始线程：Thread-2Thread-1: 2018-04-25 20:47:20.066293Thread-2: 2018-04-25 20:47:21.059349Thread-1: 2018-04-25 20:47:21.066350Thread-1: 2018-04-25 20:47:22.066407Thread-2: 2018-04-25 20:47:23.069464Thread-1: 2018-04-25 20:47:23.070464Thread-1: 2018-04-25 20:47:24.102524退出线程：Thread-1Thread-2: 2018-04-25 20:47:25.070579Thread-2: 2018-04-25 20:47:27.070693Thread-2: 2018-04-25 20:47:29.070808退出线程：Thread-2 线程之间的同步多线程同时对同一数据进行修改时，为保证数据正确，需要多线程同步。 多线程的优势在于可以同时运行多个任务（至少感觉起来是这样）。 使用 Thread 对象的 Lock 和 Rlock 可以实现简单的线程同步，这两个对象都有 acquire 方法和 release 方法，对于那些需要每次只允许一个线程操作的数据，可以将其操作放到 acquire 和 release 方法之间。如下： 考虑这样一种情况：一个列表里所有元素都是0，线程”set”从后向前把所有元素改成1，而线程”print”负责从前往后读取列表并打印。 那么，可能线程”set”开始改的时候，线程”print”便来打印列表了，输出就成了一半0一半1，这就是数据的不同步。为了避免这种情况，引入了锁的概念。 锁有两种状态——锁定和未锁定。每当一个线程比如”set”要访问共享数据时，必须先获得锁定；如果已经有别的线程比如”print”获得锁定了，那么就让线程”set”暂停，也就是同步阻塞；等到线程”print”访问完毕，释放锁以后，再让线程”set”继续。 经过这样的处理，打印列表时要么全部输出0，要么全部输出1，不会再出现一半0一半1的尴尬场面。——引自菜鸟教程，Python3 多线程 1234567891011121314151617181920212223242526272829303132333435363738394041import threadingimport datetimeimport timeclass my_Thread (threading.Thread): def __init__(self, threadID, name, delay): threading.Thread.__init__(self) self.threadID = threadID self.name = name self.delay = delay def run(self): print ("开始线程：" + self.name) threadLock.acquire() print_datetime(self.name, self.delay, 5) threadLock.release() print ("退出线程：" + self.name) def print_datetime(threadName, delay, counter): while counter: time.sleep(delay) print ("%s: %s" % (threadName, datetime.datetime.now())) counter -= 1threadLock = threading.Lock()threads = [] thread1 = my_Thread(1, "Thread-1", 1)thread2 = my_Thread(2, "Thread-2", 2)thread1.start()thread2.start()# 添加线程到线程列表threads.append(thread1)threads.append(thread2)# 等待所有线程完成for t in threads: t.join()print ("退出主线程") 输出 123456789101112131415开始线程：Thread-1开始线程：Thread-2Thread-1: 2018-04-25 20:59:31.691139Thread-1: 2018-04-25 20:59:32.691196Thread-1: 2018-04-25 20:59:33.692254Thread-1: 2018-04-25 20:59:34.692311Thread-1: 2018-04-25 20:59:35.692368退出线程：Thread-1Thread-2: 2018-04-25 20:59:37.692482Thread-2: 2018-04-25 20:59:39.692597Thread-2: 2018-04-25 20:59:41.692711Thread-2: 2018-04-25 20:59:43.692826Thread-2: 2018-04-25 20:59:45.692940退出线程：Thread-2退出主线程 注意对比区别 线程中还有线程优先级队列等，没有用到不介绍。 多进程MultiprocessingProcess 类Process 类用来描述一个进程对象，用于新建子进程。创建子进程的时候，只需要传入一个执行函数和函数的参数即可完成 Process 示例的创建。 start() 方法启动进程， join() 方法实现进程间的同步，等待所有进程退出。 close() 用来阻止多余的进程涌入进程池 Pool 造成进程阻塞。 12import multiprocessionmultiprocessing.Process(group=None, target=None, name=None, args=(), kwargs=&#123;&#125;, *,daemon=None) target 是函数名字，需要调用的函数（只要名字） args 函数需要的参数，以 tuple 的形式传入 1234567for each_group in url_groups: # 每组执行多线程下载 each_process = multiprocessing.Process(target=thread_run, args=(each_group,)) process.append(each_process)for one_process in process: one_process.start()for one_process in process: one_process.join() # 阻塞当前进程，直到调用join方法的那个进程执行完，再继续执行当前进程。 Pool类同时创建多个进程也可用Pool类 123456pool = multiprocessing.Pool(processes=4) # 创建4个进程for i in xrange(10): msg = "hello %d" %(i) pool.apply_async(func, (msg, ))pool.close() # 关闭进程池，表示不能在往进程池中添加进程pool.join() # 等待进程池中的所有进程执行完毕，必须在close()之后调用 pool.apply_async()是apply()的并行版本， apply()是apply_async()的阻塞版本，也是Python内置的函数，两者等价。在这个函数中输出结果并不是按照代码for循环中的顺序输出的。 pool.apply_async(func, (msg, ))可返回值，它返回pool中所有进程的值的对象（注意是对象，不是值本身）。 成果 #源代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586import csvimport urllib.requestimport timefrom threading import Threadimport multiprocessingimport datetime'''断点续传程序'''def get_urls(): to_down = open('weibo.csv', 'r', encoding='utf-8', newline='') csv_data = csv.reader(to_down) download_urls, downloaded_urls = [], [] count = 0 for data in csv_data: if data[9] == '': pass elif len(data[9].split(',')): # 读入数据为urls字符串，去除无用字符转为url—list for num in range(len(data[9].split(','))): # print(num) download_urls.append(data[9].split( ',')[num].strip('[').strip(']').strip(' ').strip('\'')) print(str(count) + ' Done!') count = count + 1 else: print('Error') return download_urls'''下载图片程序'''def download_pics(urls, thread_id): folder_path = '''保存路径''' fout = open('failed_pics.txt', "a", encoding='utf-8') 下载失败 保存链接 print('thread: %d is running' % (thread_id)) for url in urls: try: urllib.request.urlretrieve(url, folder_path + url.split('/')[-1]) time.sleep(1) print('pic: ' + url.split('/')[-1] + ' done!') except: print(url, file=fout) # 下载失败 保存链接 print('pic: ' + url.split('/')[-1] + ' failed!') def thread_run(download_urls): # 多线程 for i in range(0, 10): try: t = Thread(target=download_pics, args=(download_urls, i)) t.start() except: print('wrong')def multi_process(urls): # 多进程 process = [] url_group_0 = [] url_group_1 = [] url_group_2 = [] url_group_3 = [] for index in range(len(urls)): # 将url分为四组 if index % 4 == 0: url_group_0.append(urls[index]) elif index % 4 == 1: url_group_1.append(urls[index]) elif index % 4 == 2: url_group_2.append(urls[index]) elif index % 4 == 3: url_group_3.append(urls[index]) url_groups = [url_group_0, url_group_1, url_group_2, url_group_3] for each_group in url_groups: # 每组分多个进程、线程下载 each_process = multiprocessing.Process(target=thread_run, args=(each_group,)) process.append(each_process) for one_process in process: one_process.start() for one_process in process: one_process.join() # 阻塞当前进程，直到调用join方法的那个进程执行完，再继续执行当前进程。if __name__ == '__main__': start_time = datetime.datetime.now()# 用于统计时间 download_urls = get_urls() multi_process(download_urls) end_time = datetime.datetime.now() print(end_time - start_time)]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>多进程</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[吉林大学外网成绩查询]]></title>
    <url>%2F2018%2F04%2F25%2F2018-04-25-jlucjcx%2F</url>
    <content type="text"><![CDATA[毕业后才弄出来，当时绩点5分一档我各种89真的恶心（还是自己不厉害），用于在吉林大学外网查询成绩，绩点等，可稍加改进后用于各种算法算绩点。 概述用python写了个脚本，能把成绩都爬下来，然后各种算绩点的方法就可以用了（不过现在似乎没什么用，如果想的话可以把教学号密码写入了一键查)。只是为了试下模拟登录，当时发现传的加密密码放弃了，一直不懂怎么破解，后来突然发现是‘UIMS’+教学号+密码的md5加密，而且就写在网站的js代码里，uims没法登就不试了，不过那个好像比较难一点，现在加了个滑块，不然倒是可以写个自动教学评价的脚本- - 水平有限，强行用了类来实现，不过好像不怎么规范。。。 目标是通过小程序实现，看了下要学java什么的。。。python写的只能后台，这个都不太会，强行先占个坑吧。。以后再说= = 源代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123import requestsimport hashlibimport jsonimport timeimport osdef get_j_pwd(stu_id, pwd): j_pwd = 'UIMS' + stu_id + pwd m = hashlib.md5() # print(str) m.update(j_pwd.encode("utf8")) # 否则编码不同 j_pwd = m.hexdigest() return j_pwddef generate_term_id(): # 生成2005到现在的term_id current_year = time.localtime(time.time())[0] term, year_start, termID_start = 1, 2005, 101 termID_dict = &#123;&#125; while(year_start &lt;= current_year): termID_dict[str(termID_start)] = str(year_start) + \ ' - ' + str(year_start + 1) + '学年第' + str(term) + '学期' term = term + 1 if(year_start &lt; 2013): # 2013年前有3个学期 if(term == 4): term = 1 year_start = year_start + 1 else: if(term == 3): term = 1 year_start = year_start + 1 termID_start = termID_start + 1 print(u'ID\t学期') for key, item in termID_dict.items(): print(key, u'\t', item)class JLU_CJCX(): def __init__(self, stu_id, j_pwd): self.url_secucheck = 'http://cjcx.jlu.edu.cn/score/action/security_check.php' # 密码验证网址 self.url_score = 'http://cjcx.jlu.edu.cn/score/action/service_res.php' # 成绩查询网址 self.headers = &#123; 'Connection': 'keep-alive', 'Referer': 'http://cjcx.jlu.edu.cn/score/userLogin.php', 'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3386.1 Safari/537.36', &#125; # requests请求头 self.post_data = &#123; 'j_username': stu_id, 'j_password': j_pwd, &#125; self.stu_id = stu_id self.reuqest_session = requests.Session() # 需要保存cookies 构建session def log_in(self): self.reuqest_session.headers.update(self.headers) temp = self.reuqest_session.post( self.url_secucheck, data=self.post_data).text self.reuqest_session.cookies.update(self.reuqest_session.cookies) if temp[1] == '!': # 检测返回网页第一个数值 若成功则为！ print('登录成功！') return True else: print('登录失败') return False @staticmethod # 静态方法 在另一个方法中调用 def get_term_id(): term_id = int(input('请输入要查询学期的id（查询所有学期：0，查看id：1，退出：-1: ')) while(term_id == 1): generate_term_id() term_id = int(input('请输入要查询学期的id（查询所有学期：0，查看id：1，退出：-1: ')) return term_id def get_score(self): term_id = self.get_term_id() if term_id == 0: # 查所有学期 post_term_id = json.dumps(&#123;'tag': 'lessonSelectResult@oldStudScore', 'params': &#123; 'xh': self.stu_id&#125;&#125;) # json.dumps()用于将dict类型的数据转成str elif term_id &gt; 1: post_term_id = json.dumps(&#123;'tag': 'lessonSelectResult@oldStudScore', 'params': &#123; 'xh': self.stu_id, 'termId': term_id&#125;&#125;) # json.dumps()用于将dict类型的数据转成str else: print('退出') exit(0) response = self.reuqest_session.post(self.url_score, data=post_term_id) return response def UI(self): has_log_in = self.log_in() if has_log_in == False: # 登录失败退出 os.system('pause') exit(1) else: generate_term_id() while True: score_data = self.get_score() score_data = score_data.content.decode('utf-8') # 数据经过utf8编码 score_data = json.loads(score_data) if score_data['count'] == 0: print('查询成绩失败') else: print(u'课程名称\t\t\t成绩\t学分\t绩点\t重修') for item in score_data['items']: print('&#123;kcmc:&lt;&#123;len&#125;&#125;\t'.format(kcmc=(item["kcmc"][:15]), len=25 - len((item["kcmc"][:15]).encode('GBK')) + len( (item["kcmc"][:15]))), item["cj"], '\t', item["credit"], '\t', item["gpoint"], '\t', item["isReselect"]) # 为了格式对齐 os.system('pause') # 任意键继续if __name__ == '__main__': stu_id = input('教学号：') pwd = input('密码：') j_pwd = get_j_pwd(stu_id, pwd) jlu_cjcx = JLU_CJCX(stu_id, j_pwd) jlu_cjcx.UI()]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
        <tag>模拟登录</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[学习笔记之爬虫(2):豆瓣电影top250]]></title>
    <url>%2F2018%2F01%2F16%2F2016-01-06-douban%2F</url>
    <content type="text"><![CDATA[概述学了两星期了，在此之前看的比较散，原理上太薄弱，所以想重新学一下，目前还是用BeautifulSoup和requests来做，很大一部分网站都能够顺利解析并获取想要的数据，试了小猪，58同城，现在自已写了豆瓣的爬虫，就当是对刚学知识的巩固，积累经验，并做下一部学习的准备。（就不说今天兴致勃勃爬微博，结果发现微博数据全是由js加载时那种想哭的冲动了，我学还不行嘛）就按我写的思路贴代码吧 代码先列出所有用到的库（当然这是在写的过程中慢慢加的） 123456from bs4 import BeautifulSoupimport requestsimport timeimport csvimport refrom multiprocessing import Pool 初始设置的一些参数 12345678start_url = 'https://movie.douban.com/top250' # 初始url# https://movie.douban.com/top250?start=0&amp;filter= # 分析url组成fieldnames = ['title', 'director','year','rate','desc','popu'] # csv表头 输入dict与输出csv对应关系# 用于伪装成浏览器headers = &#123; 'User-Agent':'', 'Cookie':''&#125; 首先是要获取所有待爬取的链接，发现这是可以从页面底部的页码中获取的，不过没有当前页面，需要额外添加 123456789101112131415'''获取所有待爬取url函数'''def get_all_links(url): wb_data = requests.get(url,headers = headers) soup = BeautifulSoup(wb_data.text, 'lxml') links = soup.select('div.paginator &gt; a') all_links = [] all_links.append(start_url) # 没有这一条会错过top25 for link in links: # print(link.get('href')) all_links.append(start_url + link.get('href')) #将相对地址变成绝对地址 # print(all_links) #用于测试 return all_links 然后是对单一页面进行分析，构建函数提取数据，这一过程是最麻烦，但也是最有趣的。用到的工具可以有很多就看基本功和智商了233 1234567891011121314151617181920212223242526272829303132333435'''获取单页信息函数''''''!important,实际使用过程中发现，有的电影没有description时，之后的desc会错位，并错过当页最后一个电影''''''目前没有太有效办法，想到的就是从上一级就获取数据，这样无非就是再复杂化筛选过程，不太经济，保留bug'''def get_one_page_info(url): wb_data = requests.get(url,headers = headers) soup = BeautifulSoup(wb_data.text, 'lxml') titles = soup.select('div.hd &gt; a') directors = soup.select('div.bd &gt; p:nth-of-type(1)') years = soup.select('div.bd &gt; p:nth-of-type(1)') rates = soup.select('span.rating_num') descs = soup.select('div.bd &gt; p.quote &gt; span') popus = soup.select('div.bd &gt; div &gt; span:nth-of-type(4)') # print(names,directors,years,rates,descs) data_list = [] for title,director,year,rate,desc,popu in zip(titles,directors,years,rates,descs,popus): # 调试用函数,可以对每一项先打印其字符串形式，然后再想办法选出数据 # print(repr(year.get_text())) # 以字符串样式打印，便于筛选数据 # print(re.findall(r'\d+',year.get_text())) # print(desc.get_text().strip('\n')) # print("===") # 分隔 # date = re.findall(r'\d+',year.get_text()) time.sleep(3) data = &#123; 'title': title.get_text().strip('\n').replace('\n\xa0',' ').replace('\xa0',' '), # 替换掉无关字符 'director': director.get_text().strip('\n').strip().split('\xa0\xa0\xa0')[0], 'year': re.findall(r'\d+',year.get_text())[0],# 正则表达式，选出数字 'rate': rate.get_text(), 'desc': desc.get_text().strip('\n'), 'popu': re.findall(r'\d+',popu.get_text())[0], &#125; # print(data) data_list.append(data) return data_list# get_one_page_info('https://movie.douban.com/top250?start=100&amp;filter=') # 用于测试 由于数据规模小，重点是数据库没用熟，因此想到输出成csv文件，为了避免数据爬完后丢失，想办法爬一页写入一页，用追加方式打开，使光标位于文尾。 12345678910'''写入csv文件函数'''def dict_writer(dict_datas,fieldnames): with open('top250.csv', 'a',encoding = 'utf-8',newline = '') as f: # 'a' 以追加方式打开文件，encoding 则是因为有中文，newline防止输出额外空行 # fieldnames = ['title', 'director','year','rate','desc'] writer = csv.DictWriter(f, fieldnames=fieldnames) #writer.writeheader() # 写表头 for dict_data in dict_datas: writer.writerow(dict_data) 最后便是综合以上的，写出一个函数用于遍历并爬取所有的url，并后期测试了多进程爬取 1234567891011121314151617181920212223'''获取所有信息函数'''def get_pages_info(url): all_links = get_all_links(url) data = [] for link in all_links: data = get_one_page_info(link) dict_writer(data,fieldnames) print('One page done!') # 提示一页完成 time.sleep(5) '''用于多进程测试''' # data = get_one_page_info(url) # dict_writer(data,fieldnames) # print('One page done!') # 提示一页完成 # time.sleep(5)if __name__ == '__main__': get_pages_info(start_url) '''用于多进程测试''' # all_links = get_all_links(start_url) # pool = Pool() # 创建进程池 # pool.map(get_pages_info,all_links) 多进程爬虫的测试是成功的（速度提高了4倍），但由于电影有排名先后，多进程时会导到输出到文件的排名会有问题（就是各页的顺序错乱），因此注释用于以后参考 存在的问题 python基础知识薄弱 由于看了没多久，第一次做实用点的，以后多练习，并了解熟悉python的各种特性 网页知识薄弱 争取多练习吧。然后有空要补下正则，网页，数据库的知识，并熟悉目前使用的各种库，工作量还是很大的。 进阶的话。。。争取吧，目前还是巩固为主]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>爬虫</tag>
        <tag>学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[学习笔记之爬虫(1):异步加载数据的爬取]]></title>
    <url>%2F2018%2F01%2F15%2F2018-1-15-crawler1%2F</url>
    <content type="text"><![CDATA[概述经过两天的学习终于完成了第一个稍微实用的爬虫，用15秒爬下了50张（哭）霉霉的图片。。。感谢仁慈的网站网开一面，由于学艺不精，暂时没加反反爬手段，只爬了前三页用于测试。实际测试已经成功，所以顺便复习下这几天学习的成果。 网页信息的的获取目前所学习的还只是通过requests来得到网页，并用BeautifulSoup调取lxml html解析器来获取网页数据 （还有效率更高的正则表达式及lxml模块）。12345678910111213from bs4 import BeautifulSoupimport requestsurl =''header = &#123; 'User-Agent':''&#125;# 'User-Agent'用于伪装成浏览器正常访问wb_data = requests.get(url,headers = header)soup = BeautifulSoup(wb_data.text,'lxml')# .text是用于获取网页的文本类型数据#'lxml'即调用lxml html解析器 网页元素的筛选BeautifulSoup支持CSSselector，因此可使用.select(),技术方法用CSS选择器的语法找到存有信息的标签目前有两种方法来选择.select()的参数（要具有唯一性特征） CSSselector直接在Chrome检查元素后copy -&gt; selector，然后选择到需要元素的父标签。这里遇到的问题是需要把nth:child改成nth-of-type然后就查了下这两个的区别，相比较nth-of-type条件更少。 选择器 条件 nth-child 这是个段落元素且它父标签的第二个孩子元素(\&lt;p>标签) nth-of-type 父标签的第二个段落子元素(\&lt;p>标签) 但后来由于要选取所有的同类标签，所以并没有在这个问题上多作纠结。 标签名是当标签名唯一时，可以使用标签名的形式来进行选择数据 获取数据的打包一个网页通过上述步骤，通常能获取许多不同链接，然后便通过循环来获得不同的数据，对于多个数据的循环用到了zip函数。123# 用于将可迭代的对象作为参数，将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的列表。如果各个迭代器的元素个数不一致，则返回列表长度与最短的对象相同。zip([iterable, ...])zip(*zipped_list) #逆操作 然后是获取数据，一般分为两类，对于标题，分类等文本信息，使用.get_text()方法获取，而对于图片或链接等则用.get(‘link’)获取，link为链接所在的属性，如src,href等。这其中涉及到的list和dict的操作不多说。在获取数据后再进一步根据下一步操作选择存储信息的方式，存于list,dict等 多页信息的爬取目前主要涉及静态网页，通过观察链接的变化，设置循环来对多页网页进行爬取，此时由于访问过于频繁，可能会触发网站的反爬虫机制，一个简单的办法是通过time.sleep()方法来设置访问间隔 123import timetime.sleep(2) # 程序停止2秒 动态加载数据的提取现在很多网站用动态加载，如新浪微博的评论，可以随鼠标的点击滚轮的运动，不停加载内容。这一过程是通过JS来完成的。对于这类网页的爬取，需要用浏览器的监视功能中（NETWORK -&gt; XHR)，在网页动态加载的过程中，查看加载的规律，对于内容的提取也应该是这样，检查加载的内容，然后分析网页中多出的html代码进而执行与之前相同的爬取步骤。 网页的下载12import urllib.requesturllib.request.urlretrieve(url, filename=None, reporthook=None, data=None) 参数filename指定了保存本地路径（如果参数未指定，urllib会生成一个临时文件保存数据。） 参数reporthook是一个回调函数，当连接上服务器、以及相应的数据块传输完毕时会触发该回调，我们可以利用这个回调函数来显示当前的下载进度。 参数data指post导服务器的数据，该方法返回一个包含两个元素的(filename, headers) 元组，filename 表示保存到本地的路径，header表示服务器的响应头 在爬取霉霉图片时定义图片文件名时还用了split方法 123456# str.split(str="", num=string.count(str)).# str设定的分隔符，默认为所有的空字符，包括空格、换行(\n)、制表符(\t)等。# num 表示分割次数。&gt;&gt;&gt;str = 'misad is'&gt;&gt;&gt;print (str.split('i',1))['m','sad is'] Show me the code12345678910111213141516171819202122232425262728293031323334353637383940414243444546# 动态数据提取from bs4 import BeautifulSoupimport requests, urllib.requestimport timeurl = 'https://weheartit.com/inspirations/taylorswift?scrolling=true&amp;page='header = &#123; 'User-Agent': '', &#125;def get_page(url, data = None): wb_data = requests.get(url,headers = header) soup = BeautifulSoup(wb_data.text, 'lxml') imgs = soup.select('img.entry-thumbnail') one_page_img_url = [] for img in imgs: one_page_img_url.append(img.get('src') ) print(one_page_img_url) return one_page_img_urldef get_more_pages(start,end): imgs_url = [] for one in range(start,end): one_page_img_url = get_page(url+str(one)) time.sleep(4) imgs_url.extend(one_page_img_url) print(imgs_url) return imgs_urldef download_links(links): folder_path = '' for link in links: urllib.request.urlretrieve(link, folder_path + link.split('/')[-2] + link.split('/')[-1])imgs_url = get_more_pages(1,3)download_links(imgs_url)]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>爬虫</tag>
        <tag>学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[学习笔记之数据可视化（1）：世界GDP图_Pygal]]></title>
    <url>%2F2018%2F01%2F11%2F2018-01-11-pygal%2F</url>
    <content type="text"><![CDATA[概述这几天在看爬虫，感觉现在黄金时期已经过去了，各网站反爬的手段也是越来越高明了，昨天就多访问了某网几ip就被封了，所以这上面的学习可能需要蛮久，战线会很长。所以就顺便先做做数据可视化吧，为以后做准备。此文先作个引子，希望以后加强学习多敲代码。 2016全球GDP图在世界银行网站上下了世界GDP从1960-2016的数据，然后使用pygal中提供的图表类型Worldmap，制作呈现各图数据的世界地图(.svg文件)。在本地打开鼠标悬停可显示数据 文件编码还没开始处理数据就遇到问题了1&gt;&gt;&gt;with open(filename) as f: 提示错误1UnicodeDecodeError: &apos;gbk&apos; codec can&apos;t decode bytes 0xbf in position 2: illegal multibyte sequence． 这是由于python3默认解码方式失败导致的，比如它可能发现了中文用gbk去解码，但文本是utf-8的所以会失败，因此，只需要在打开文件时指定解码方式就可以解决。1&gt;&gt;&gt;with open(filename,encoding='UTF-8') as f: 迭代器切片由于下载数据是从第四行开始有数据的，每次在循环中判断将加在时间开销，因此需要另想办法来处理。经过查看文档csv.reader()发现返回数据是一个迭代器，就想到了处理迭代器中的函数islice()123&gt;&gt;&gt;# islice用于切片操作&gt;&gt;&gt;islice(iterable, [start,] stop [, step]) &gt;&gt;&gt;#iterable可迭代变量，start起始值可省略，stop终止值，step步长 列出索引123&gt;&gt;&gt;head_row = next(gdp_data)&gt;&gt;&gt;for index,column_header in enumerate(head_row): #列出索引... print(index, column_header) 可以列出文件头及索引，这样就可以方便获取数据。其中123enumerate(iterable, [start=0])# iterable -- 序列、迭代器或其他可迭代对象。# start -- 下标起始值。 数据处理国别码处理数据处理的话就是要从一行行数据中取出所需要的国家名和对就年分的GDP值，并组成字典。这其中有个问题就是Pygal中使用两个字母的国别码，而在文件中是三个字母的，这需要使用 pygal.maps.world.COUNTRIES: 中的字典 COUNTRIES 进行转换(pygal - 2.0.0 以前此字典的模组pygal.i18n中)，因此使用2.0.0以后版本可以这样来使用相应模组 1234567891011# pip install pygal_maps_world. &gt;&gt;&gt;from pygal.maps.world import COUNTRIES# from pygal_maps_world import i18n&gt;&gt;&gt;def get_country_code(country_name):... for code,name in COUNTRIES.items(): ... # items()方法把字典中每对key和value组成一个元组，并把这些元组放在列表中返回。... if name == country_name:... return code... return None GDP数值处理在获取GDP过程中，需要对读入数据进行处理，把字符串str类型转换成float类型用于Pygal作图，但直接转换会有问题，由于有的国家2016年的GDP数据缺失，导入数据是空字符，若float(‘’)会出现1could not convert string to float # 不能把字符串转换为浮点类型的错误 我加入了if循环将空字符变为‘0’在此过程中，可能有时字符中有特殊字符导致转换失败，可以用1&gt;&gt;&gt;print(repr(string)) 以字符串形式打印数据，检查是否包含数字以外字符，再找办法处理 在获取GDP数值后还可以对GDP数值进行分类，以便显示时细化区分 绘图绘图时需要用到基本的pygal知识，这个想另外介绍，因为目前知道的也有限，仅说本文用的几行程序 123456&gt;&gt;&gt;wm = pygal.maps.world.World() # 构建地图&gt;&gt;&gt;wm_style = RotateStyle('#336699') # 设置图表颜色 16进制颜色&gt;&gt;&gt;wm = pygal.maps.world.World(style = wm_style)&gt;&gt;&gt;wm.title = 'World GDP in 2016,by country' # 图表标题&gt;&gt;&gt;wm.add('GDP',Country_GDP) # 导入数据&gt;&gt;&gt;wm.render_to_file('world gdp.svg') # 生成svg文件]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Pygal</tag>
        <tag>数据可视化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[听录习总10.25新闻见面会发言]]></title>
    <url>%2F2017%2F10%2F26%2F2017-10-26-pressmeeting%2F</url>
    <content type="text"><![CDATA[常委见面会讲话发言的英文，小哥读得实在是标准得不行，虽然不是美音或者英音，但能这样子真的也是超级棒了，听录下来学习下。Ladies and gentleman, comrades and friendsGood morningThe 19th national congress of the Communist Party of China was concluded yesterday. The party congress has received extensive and detailed reporting via friends from the press, with many of you coming from afar. You have worked very hard and your media coverage has captured the attention of the world. I want to say a big thank you to you all.Since the opening of the party congress, 452 major political parties and 165 countries have sent 855 messages of congratulation. Of these 814 came from heads of state or government or the leaders of political parties or important organizations. On behalf of the CPC central committee, I wish to convey our sincere appreciation to them all.We have just held the first plenary session of the 19th central committee and elected a new central leadership. I was re-elected general secretary of the CPC central committee. I see this as not just approval of my work, but also encouragement that will spur me on.Now I wish to present to you the other six members who have also been elected to the standing committee of the political bureau.Comrade Li Keqiang, Comrade Li Zhanshu, Comrade Wang Yang, Comrade Wang Huning, Comrade Zhao Leji, Comrade Han Zheng.Comrade Li Keqiang served on the political Bureau’ standing committee of the 18th CPC central committee. While all the others were the member of the political Bureau of the 18th CPC central committee. You can learn more about them from the media.Here, on behalf of the newly elected central leadership, I wish to express our heartfelt thanks to all other members of the party, for the trust they have placed in us. We will work diligently to meet our duty, fulfill our mission and be worthy of their trust.Over the past five years, we have set out a broad agenda. Some tasks have been completed, while others need more work. This party congress has set new goals and new tasks. We must make coordinated efforts to see them through.With decades of hard work, socialism with Chinese characteristics has entered a new era. In this new contest, we must get a new look, and more importantly make new accomplishments. The coming five years, between the 19th and 20th party congress, is a period in which the time frames of the two centenary goals will converge. Not only must we deliver the first centenary goal, we must also embark on the journey towards the second centenary goal. As I look ahead to the next five years, I see several important junctures and sign posts.In 2018, we will mark the 40th anniversary of the launch of the reform and opening-up. Reform and opening-up is a crucial move that is shaping China’s future. 40 years of reform and opening-up has made it possible for our people to lead decent and even comfortable lives. We will review our experience and build on the good momentum to continue modernizing China’s system and capacity for governance, and make determined efforts to comprehensively deepen reform and open China still wider to the world. We will see that reform and opening-up complement and reinforce each other. It is my conviction that the great rejuvenation of the Chinese nation will become a reality in the course of reform and opening-up.In 2019, we will mark the 70th anniversary of the founding of the People’s Republic of China. We will act on the new vision for development and strive a sustained and healthy economic growth that benefits people in China and around the world. We will continue our efforts to accomplish all the tasks left down in the 13th five-year-plan, develop new blueprints for China’s future and see the flourishing of all our endeavors. These efforts will contribute towards a more prosperous and strong People’s Republic.In 2020, we will establish a moderately prosperous society across all metrics. This is a society to be enjoyed by each and every one of us. On the march towards common prosperity, no one must be left behind. We will mobilize the whole party and whole country in the resolute push to deliver on our pledge and eradicate poverty in China. The aspersions of the people to live a better life must always be the focus of our efforts. We must remain committed to people-centered philosophy of development, strive to ensure and improve living standards, and make steady progress towards enhancing our people’s sense of fulfilment, happiness and security and towards realizing common prosperity for everyone. I have no doubt in my mind that our people’s lives will see further improvement year after year.In 2021, we will mark the centenary of the Communist Party of China. For the party which fights for the eternal well-being of the Chinese nation, the centenary only ushers in the prime of life. As the world’s largest political party, the CPC must behave in a way commensurate with this status. Its history makes it abundantly clear that the CPC is capable of not only spearheading a great social revolution, but also imposing a great reform on itself. We, as its members, must always have a youthful spirit and forever be the servants of the people, the vanguard of the times and the backbone of our nation. Exercising full and rigorous governance over the party is a journey to which there is no end. We should never entertain the idea of taking a breather or halting our steps. Instead we must continue to rid ourselves of any virus that erodes the party’s fabric, make great effort to foster a healthy political environment of integrity and generate waves of positive energy throughout our party, which can then building into a mighty, nation-wide force, driving China’s development and progress.The Communist Party of China and Chinese people have gone through trials and tribulations. These experiences have taught us that peace is precious and development must be valued. With confidence and pride, the Chinese people will be steadfast in upholding our country’s sovereignty, security and development interests. We will also work with other nations to build a global community with a shared future and make new and greater contributions to the noble course of peace and development for all humanity.The people are the creators of history. It is to them that we own all our achievements. As long as we firmly align ourselves with our people and rely on them, we can and will have boundless energy to forge ahead, come rain or shine.As the saying goes, it is better to see once than to hear a hundred times. We encourage members of the press to visit and see more of China. We hope that, after the party congress, you will continue to follow china’s development and progress, and learn about and report on more dimensions of China.We do not need lavish praise from others; however, we do welcome objective reporting and constructive suggestions, for this is our motto, ‘not angling for complements, I’d be content let my integrity feels the universe.’Thank you.]]></content>
      <categories>
        <category>日记</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tenda(腾达)W311R无线路由器开WISP]]></title>
    <url>%2F2017%2F10%2F14%2F2017-10-14-tendawisp%2F</url>
    <content type="text"><![CDATA[首先祝贺获奖，反正你是最厉害的。然后就是今天做的。（现在真的是做什么都没那么有激情了）本来准备把原来的路由器和电信的光猫进行WDS桥接，但似乎是由于不同品牌，试了一整天都没有成功，期间改变各种变量，并重置了多次，最后只能重新买了一个路由器dlink dir859; 这款功率真的不错，开中级就能基本覆盖了。然后多了一台老路由TP-Link WR740N，拿到乡下与原来的路由Tenda W311R桥接，发现仍然不行。并多次改变了主从路由，即便可以ping通，电脑仍显示无法连接英特网（血与泪的教训，买路由器要买同一品牌）。由于电信网络电视的限制（专线)，因些尝试把一台当交换机用也不行，最后只能无奈刷固件。比较了下两台路由器，并查了些资料后，发现W311R可以通过刷万能中继固件实现WISP,WISP比起WDS简直方便太多，可以兼容任何上级品牌的无线路由器信号。关于各种定义慢慢总结介绍，这几天记了好些笔记。首先介绍W311R刷固件方法 刷固件前首先要确认W311R处理芯片的型号W311R有后面有两个螺丝在两个缓冲脚垫后，拧下后从后面向两侧撬开，两侧各有一个卡口，而前脸（灯两边下也有两个）的两个可能要用螺丝刀从里而捅戳一下，从外面很难弄开，因此一开始要幅度不要太大。我是直接撬起了点看了下处理器型号（方形黑片），按网上的说法如果能看到5356那就是可刷的，如果5356后面是COKFBG成功率会高，而LKFBG和AIFBG成功率低，我的是LKFBG第一次刷成功变砖，正感叹并准备以后有空再买TTL线之时，天无绝人之路，发现可以挽回，喜欢折腾的可以试下 下载固件包链接：http://pan.baidu.com/s/1gf09QUZ 密码：x6me 首先刷.trx文件具体的办法就不多介绍了，就是登录管理界面，建议使用网线连lan口（四个黄色口)升级（我在后面升级发现无线连接传输失败的问题），然后把系统版本升级成v5.07.50cn(如果已经升级到了就不需要，在上传框下面会有小字显示)，上传升级后等待重启就可以了，重连接后可以按reset初始化一下，等待再次连接PS：升级过程中不能断电，否则没救了 然后刷.bin文件过程同上，刷完如果不能连接初始化一下，如果还不行，多半是变砖了（拔了电源重插后只有电源指示灯亮）我当时就是到了这一步。 连主路由无线当然成功的同学就可以看到一个全新的控制界面，只要界面里找到无线网络，无线放大器扫描后输入密码就可以了。 下面介绍的是变砖后的补救办法。1.通过网线连接，然后把ip地址设置为192.168.0.2，运行windows控制台，ping 192.168.0.1即路由器的lan口，如果能通，说明有救；2.在控制台下，输入appwiz.cpl，打开程序和功能 - 打开或关闭windows功能，勾选tftp客户端安装，3.给路由器上电后，长按reset半分钟，然后拔掉电源4.在cmd控制台中先输入tftp -i 192.168.1.1 put c:\tengda.trx(刚刚下载的trx文件路径)5.接通电源同时控制台输入回车，显示传输成功就得救了，可以试试另找固件包再刷。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017.09.13]]></title>
    <url>%2F2017%2F09%2F13%2F2017-09-13%2F</url>
    <content type="text"><![CDATA[9.13记相信自己的选择无论怎样这是你与别人一直以来的区别做不到的我是不会说的但是无论怎样你一定会是很特殊的 17号考托福，感觉这次复习得一塌糊涂，不过也没什么好说的，等弄完再考虑别的很多事真的真的超级难的，我希望我是一直努力的，就这点希望还是好的吧不过最后考虑了下，四年真的过得太平淡了，虽然一直的性格是这样，但也正是因为这样吧]]></content>
      <categories>
        <category>日记</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017.09.03]]></title>
    <url>%2F2017%2F09%2F03%2F2017-09-03%2F</url>
    <content type="text"><![CDATA[9.03记像我这样的人，这么随心，不喜欢被束缚，这么挑剔，这么喜欢稳定，这么理想化如今又努力做什么呢现在真的不知道该怎么办才好我也蛮无奈啊也许遇见只是个意外吧真的是蛮意外的了哪来什么以后，不以后在看了好多集yes,minister之后在经历了邻里纠纷之后我深刻的知道了Knowledge only means complicity and gulitIgnorance has some dignity和自已的无知也简单的理解了，或许一生就是仅是这样吧不应该抗争什么，特别是为了一点点感觉想想真是又气又好笑自己真是太胆小了]]></content>
      <categories>
        <category>日记</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git Commit的书写规范]]></title>
    <url>%2F2017%2F07%2F24%2F2017-07-24-gitcommit%2F</url>
    <content type="text"><![CDATA[晚上搜资料发现原来git commit的message也有书写规范，学习下比较常用的是Angular书写规范，如下12345&lt;type&gt;(&lt;scope&gt;): &lt;subject&gt;&lt;body&gt;&lt;footer&gt; 由于我现在所写的程序比较简单，所以比较重要的是type和subject1）type分为以下七个： feat：新功能（feature） fix：修补bug docs：文档（documentation） style： 格式（不影响代码运行的变动） refactor：重构（即不是新增功能，也不是修改bug的代码变动） test：增加测试 chore：构建过程或辅助工具的变动 2）subject是commit目的简短描述 以动词开头，使用第一人称现在时，比如change，而不是changed或changes 第一个字母小写 结尾不加句号（.） 而scope是说明commit影响的范围body是详细说明footer则用于不兼容变动等情况时以上三种等用到时再详加说明。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于git常用命令的介绍]]></title>
    <url>%2F2017%2F07%2F24%2F2017-07-04-git-command%2F</url>
    <content type="text"><![CDATA[刚刚开始学python的时候接触了git，虽然现在没有做大项目，但git的功能真的是太强大了，简单记录下常用的几个命令。 初始化git init切换到相应文件夹后用此命令可以初始化一个git仓库 检查状态git status用于检测仓库中有哪些文件初修改了，增加或删除了哪些文件等 将文件加入仓库git add filename.xxx用于添加文件另外还有几个更方便的命令git add -A提交文件夹下所有文件改动到暂存区git add .提交工作区变化到暂存区，包括新文件但不包括被删除文件git add -u提交被add文件改动到暂存区，不包括新文件，但包括被删除文件 执行提交git commit -m &quot;message&quot;提交修改，message中可以加入些改动说明 重命名文件git mv oldfilename.xx newfilename.xx]]></content>
      <categories>
        <category>备忘</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sublime3中调用cmd终端]]></title>
    <url>%2F2017%2F07%2F23%2F2017-07-23-pythonterminal%2F</url>
    <content type="text"><![CDATA[最近在学习python，由于sublime的控制台不能支持输入，经常是一边敲代码一边复制到cmd终端，偶然发现可以配置sublime中的termianl插件支持直接调用终端，具体方法如下： 安装直接在sublime中输入ctrl+shift+p，然后输入install package或pcip进入安装插件列表，然后输入terminal安装插件 配置安装完成后，在sublime中打开Preferences - Package Settings - Termial - Settings User，然后在窗口中根据自己的终端路径输入如下代码123456&#123; // window下终端路径 &quot;terminal&quot;: &quot;C:\\Windows\\System32\\cmd.exe&quot;, // window下终端参数 &quot;parameters&quot;: [&quot;/START&quot;, &quot;%CWD%&quot;] &#125; 如果是Linux系统则为123&#123; &quot;terminal&quot;: &quot;xterm&quot;&#125; OS X:123&#123; &quot;terminal&quot;: &quot;iTerm.sh&quot;&#125; 由于本人系统是windows所以其他两种并未尝试，可自行试验。 运行ctrl+shif+T就可以运行弹出终端了]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>sublime</tag>
        <tag>cmd</tag>
        <tag>terminal</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown语法说明]]></title>
    <url>%2F2017%2F07%2F19%2F2017-07-19-markdown%2F</url>
    <content type="text"><![CDATA[由于刚接触markdown，因此通过本文记录markdown语法，防止经常不必要的检索 基本语法无序列表123* test+ test2- test3 test2 test3 test4 有序列表121. test2. test test test 分割线1*** 下面是分割线： 博文的截取1&lt;!-- more --&gt; 在需要截断的地方添加这个标签，可以精准截断； 表格123标题1| 标题2 | 标题3-----| ----- | -----行1列1| 行1列2| 行1列3 标题1 标题2 标题3 行1列1 行1列2 行1列3 删除线1~~删除~~ 删除 字体、字号、颜色的更改在markdown中更改字体大小及颜色可以使用html语法123&lt;font size=4 &gt; 自定义字体大小 &lt;/font&gt;&lt;font color="#FF0000"&gt; 自定义字体颜色 &lt;/font&gt; &lt;font color="blue"&gt; 自定义字体颜色 &lt;/font&gt; 效果如下: 自定义字体大小 自定义字体颜色 自定义字体颜色 123456&lt;small&gt;&lt;small&gt;最小字号&lt;/small&gt;&lt;/small&gt;&lt;small&gt;小字号&lt;/small&gt;&lt;big&gt;大字号&lt;/big&gt;&lt;big&gt;&lt;big&gt;大大字号&lt;/big&gt;&lt;/big&gt;&lt;big&gt;&lt;big&gt;&lt;big&gt;大大大字号&lt;/big&gt;&lt;/big&gt;&lt;/big&gt;&lt;big&gt;&lt;big&gt;&lt;big&gt;&lt;big&gt;继续加可以继续大下去&lt;/big&gt;&lt;/big&gt;&lt;/big&gt;&lt;/big&gt; 最小字号小字号 大字号大大字号大大大字号继续加可以继续大下去 而字体的设置详见NexT使用文档;]]></content>
      <categories>
        <category>备忘</category>
      </categories>
      <tags>
        <tag>markdown</tag>
        <tag>语法</tag>
        <tag>备忘</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[布署Nginx和Gunicorn时遇到的问题]]></title>
    <url>%2F2017%2F07%2F19%2F2017-07-19-nginxgunicorn%2F</url>
    <content type="text"><![CDATA[写这篇文章是自己在做个人博客时的一些经验，在这几天的选择中，先后用了Python+Django，wordpress和hexo，最后决定暂时先用hexo应付，最终争取用python+Django自己完成博客的搭建。一开始做博客参考的是追梦人物的博客教程，在做到发布前可以说介绍的非常详细，我按照教程也基本都做出来了，但到了发布则相当的简略，涉及到诸多问题。为些记录下我的发布历程，方便以后再次发布。一直到启动Nginx服务这里都可以按照他博客介绍的做，但由于nginx中有默认配置，所以很多人会看到欢迎页面而不是12(env) yangxg@localhost:~/sites/demo.zmrenwu.com/django-blog-tutorial$ python manage.py makemigrate(env) yangxg@localhost:~/sites/demo.zmrenwu.com/django-blog-tutorial$ python manage.py migrate 如果看到欢迎页面是DefaultPages，仍可以继续往下做接着就按照部署代码中的步骤完成代码部署前的项目配置、在github的上传等，其中生成数据库时我提示错误，然后按照提示内容操作了下具体是直到配置Nginx，配置Nginx的具体方法是：（因为第一次没成功，我没有在虚拟环境中进行，此文仅还原我的操作过程）首先在Xshell中输入1yangxg@localhost:~/sites/demo.zmrenwu.com/django-blog-tutorial$ cd 退出到根目录然后12yangxg@localhost:$ cd /etc/nginx/sites-available/yangxg@localhost:/etc/nginx/sites-available/$ sudo vi default 如果提示输入密码就输入之前设置的密码，然后就可以直接按照教程修改default文件中的配置内容（如果要新建文件夹并新建配置文件也可以，但应该要删除default文件）删除命令是1yangxg@localhost:/etc/nginx/sites-available/$ sudo rm default 配置修改完成后按Esc，然后输入:wq进行保存，然后我重新进入按之前的步骤进入虚拟虚拟然后发送配置文件到sites-enabled/目录1yangxg@localhost:~/sites/demo.zmrenwu.com/django-blog-tutorial$ sudo ln -s /etc/nginx/sites-available/demo.zmrenwu.com /etc/nginx/sites-enabled/demo.zmrenwu.com]]></content>
      <categories>
        <category>博客搭建</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>博客</tag>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017.7.18]]></title>
    <url>%2F2017%2F07%2F18%2F2017-7-18%2F</url>
    <content type="text"><![CDATA[最近做的事7月13号考完后有点浪，学习得很盲目，但这几天终于睡得不错了。这几天主要是在构想自己的博客，初步计划是用Python+Django做，已经按教程做完并布署了，但由于细节太麻烦，但又不想轻易放弃因此考虑在本地研究，并通过markdown记录。为了好发布，因此也考虑用其他先暂时充数，首先考虑的是wordpress，还是喜欢动态博客而且正好有多的服务器，但弄完发现有点不太适合我。一是没有markdown，二是主题要好看也要订制，比较麻烦，因此我考虑使用hexo。hexo+github是比较轻量化的博客，静态，但布署简单，做好很难，现在用的是别人做的模版，做这个确实不会，所以只能参考了。今天大致弄完了，以后就可以安心发文章并且研究别的了。最近是真的不想想别的事了，很难过。]]></content>
      <categories>
        <category>日记</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[89C51与AD0832波形输出]]></title>
    <url>%2F2017%2F07%2F18%2F2017-07-18-waveoutput%2F</url>
    <content type="text"><![CDATA[原文是来自我的CSDN博客，用于迁移测试，练习Markdown 本次实验通过proteus仿真仿真电气连接图：本次实验通过keil编译通过，实验程序如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114#include &lt;absacc.h&gt; #include &lt;reg52.h&gt; #define DA0832 XBYTE[0xfffe] #define uchar unsigned char #define uint unsigned int sbit S1 = P1^0; sbit S2 = P1^1; //00锯齿波；01方波；10三角波；11正弦波 uchar code sin_tab[] = //正弦波输出表 &#123; 0x80,0x83,0x86,0x89,0x8D,0x90,0x93,0x96,0x99,0x9C,0x9F,0xA2,0xA5,0xA8,0xAB,0xAE, 0xB1,0xB4,0xB7,0xBA,0xBC,0xBF,0xC2,0xC5,0xC7,0xCA,0xCC,0xCF,0xD1,0xD4,0xD6,0xD8, 0xDA,0xDD,0xDF,0xE1,0xE3,0xE5,0xE7,0xE9,0xEA,0xEC,0xEE,0xEF,0xF1,0xF2,0xF4,0xF5, 0xF6,0xF7,0xF8,0xF9,0xFA,0xFB,0xFC,0xFD,0xFD,0xFE,0xFF,0xFF,0xFF,0xFF,0xFF,0xFF, 0xFF,0xFF,0xFF,0xFF,0xFF,0xFF,0xFE,0xFD,0xFD,0xFC,0xFB,0xFA,0xF9,0xF8,0xF7,0xF6, 0xF5,0xF4,0xF2,0xF1,0xEF,0xEE,0xEC,0xEA,0xE9,0xE7,0xE5,0xE3,0xE1,0xDF,0xDD,0xDA, 0xD8,0xD6,0xD4,0xD1,0xCF,0xCC,0xCA,0xC7,0xC5,0xC2,0xBF,0xBC,0xBA,0xB7,0xB4,0xB1, 0xAE,0xAB,0xA8,0xA5,0xA2,0x9F,0x9C,0x99,0x96,0x93,0x90,0x8D,0x89,0x86,0x83,0x80, 0x80,0x7C,0x79,0x76,0x72,0x6F,0x6C,0x69,0x66,0x63,0x60,0x5D,0x5A,0x57,0x55,0x51, 0x4E,0x4C,0x48,0x45,0x43,0x40,0x3D,0x3A,0x38,0x35,0x33,0x30,0x2E,0x2B,0x29,0x27, 0x25,0x22,0x20,0x1E,0x1C,0x1A,0x18,0x16,0x15,0x13,0x11,0x10,0x0E,0x0D,0x0B,0x0A, 0x09,0x08,0x07,0x06,0x05,0x04,0x03,0x02,0x02,0x01,0x00,0x00,0x00,0x00,0x00,0x00, 0x00,0x00,0x00,0x00,0x00,0x00,0x01,0x02,0x02,0x03,0x04,0x05,0x06,0x07,0x08,0x09, 0x0A,0x0B,0x0D,0x0E,0x10,0x11,0x13,0x15,0x16,0x18,0x1A,0x1C,0x1E,0x20,0x22,0x25, 0x27,0x29,0x2B,0x2E,0x30,0x33,0x35,0x38,0x3A,0x3D,0x40,0x43,0x45,0x48,0x4C,0x4E, 0x51,0x55,0x57,0x5A,0x5D,0x60,0x63,0x66,0x69,0x6C,0x6F,0x72,0x76,0x79,0x7C,0x7E &#125;; void Delay_MS(uint);// delay void stair(uchar AMP);//锯齿波 void square(uchar AMP, uchar THL,uchar TLL);//方波 void trian(uchar AMP);//三角波 void sin();//正弦波 void scan();//扫描函数 void main() &#123; while(1) &#123; //逐个测试 //stair(200); //square(200,10,10); //trian(200); //sin(); scan(); &#125; &#125; void scan() &#123; if((0 == S1) &amp;&amp;(0 == S2)) stair(200); else if((1 == S1) &amp;&amp; (0 == S2)) square(200,10,10); else if((0 == S1) &amp;&amp; (1 == S2)) trian(200); else sin(); &#125; void Delay_MS(uint n) &#123; uint k; for(n; n &gt;0 ;n--) for(k = 10; k &gt; 0 ;k--); &#125; void stair(uchar AMP) &#123; uchar i; for(i = 0 ;i &lt; 255; i++) &#123; DA0832 = i; &#125; &#125; void square(uchar AMP, uchar THL, uchar TLL) &#123; DA0832 = 255 - AMP; Delay_MS(THL); DA0832 = 255; Delay_MS(TLL); &#125; void trian(uchar AMP) &#123; uchar i; for(i = 255 - AMP ;i &lt; 255; i++) &#123; DA0832 = i; &#125; for(i-1 ;i &gt; 255 - AMP; i--) &#123; DA0832 = i; &#125; &#125; void sin() &#123; uchar i; for(i = 0; i &lt; 255; i++) &#123; DA0832 = sin_tab[i]; &#125; &#125; 其仿真输出如图所示：正弦波:三角波:方波：锯齿波：]]></content>
      <categories>
        <category>单片机</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>单片机</tag>
        <tag>电子</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017.5.20]]></title>
    <url>%2F2017%2F05%2F20%2F2017-5-20%2F</url>
    <content type="text"><![CDATA[最近的若干想法王小波&emsp;&emsp;最近看了沉默的大多数，本来应该是高中看的吧，或者更早，我却现在还在以龟速看。里面绝大多数的差点我都非法认同，放到今天也是非常适用的。今天看到的性教育及美国在一战二战时候的审查之严格和今日的中国也差不多，这方面我其实是想认同需要审查的。现在很多人宣称的自由化我并不是都认同的，但不反对是我能给的最大的支持了，任何事为了政治正确去宣扬，去加速进程，都会损害另一方的利益（虽然他们可能是目前的受益者），但每个人都有自己选择的权利，在时机没成熟之前推行，我宁愿保守。审查我觉得只是尺度的问题。就像中国建国之初的党内民主讨论会，确实是下级敢冒犯上级吧，大家都畅所欲言，现在就成了一言堂了，说到底还是知识水平不够，而现在说中国不民主，其实也是整体水平不行，而上面似乎也乐见其成。 其他&emsp;&emsp;真希望很多事都简单到有默契就好了。&emsp;&emsp;王国维在人间词话中有说： 古今之成大事业、大学问者,必经过三种之境界：第一种境界是“昨夜西风凋碧树,独上西楼,望尽天涯路”——宋·晏殊·《鹊踏枝》第二种境界是“为伊消得人憔悴,衣带渐宽终不悔” —— 宋·柳咏·《蝶恋花》第三种境界是“众里寻他千百度,蓦然回首,那人却在灯火阑珊处” ——宋·辛弃疾·《青玉案》 12life is shortlife is sigle]]></content>
      <categories>
        <category>日记</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017年计划]]></title>
    <url>%2F2016%2F12%2F31%2F2016-12-31-plan%2F</url>
    <content type="text"><![CDATA[依然还是先流水帐&gt;.&lt; 今年拿到了驾照，真心不容易，然后当晚就开了一段，后来还开了两次无锡，但开车还是要更多的练习，专注。 2月听说萌妹纸的四六级，她居然和我说什么越刷越低，她那么霸气侧漏的人怎么可以那样，所以成功刷的比她高，哈哈开心，她酷的时候真的很可爱。 2-3月全面改了五笔，真心不容易，此处应该感谢美美，多亏陪我聊天让我成功过渡。 看完了三体1，a walk to remember,冰火1，目送，失乐园，one day，蒋勋讲宋词等书，还不够，年末买了ku，明年要多看点。 上半年还看了很多p图技巧，弄出了许多自己比较满意的照片，但还差很远，还要努力学习。 没字幕看了冰火和eevblog真心不容易，但还是要坚持，对自己提高还是挺多的。 总是能在各种巧合的时候碰到萌妹纸，真的挺不容易，但还是没做到去年末的愿望要和她混熟，因为真的感觉和她三观很一致，难得碰到，也是真心喜欢，但是我还是坚持当时和女神说的那些，不应该做的坚决不做，遇到就是幸福了。每次真的特别巧，而且总是能一眼认出来。可惜没约成功= =好想问她好多好多问题。 暑假时候解决了遗憾，挺不容易。 今年在假期和爸妈出去了两次，难得陪他们出去，以后也不知道会怎样但有机会还是要一起出去玩，开心。还一起跑步，身体也渐好。 下半年基本没做什么，课也没去上，然后也没怎么出去玩，中间出去吃的一顿是和丽洁，认识很不容易，她还给我带了马来西亚的咖啡和咖喱，希望以后还能碰见她，要加油来中国哦~ 考研其实不是特别顺利，总是这样，平时很厉害的样子但到关键时刻就掉链子，其实还是比较水，但感谢小伙伴们一起努力学习让我有动力，嗯感谢萌妹纸开导我（一定是的~。也很感谢她，真的，一直是我的动力，但这样总是感觉有时候动力不足。很想约她一起说说话。。。唉= =可是都好久没有看见了。 16年没有去远的地方玩，这可能是除了和萌妹纸混熟之外唯一没完成的愿望了。。。好想有空去日本自由行。其他还有很多未尽的事都记在微信了。。去年说要少玩手机其实应该可以算是做到了，很少找人聊天了，除了有限的几个人说说，其他很少主动说。。。然后朋友圈一直发是因为把它当日记了。。挺不错的。 16年应该依旧很平凡，关于17年，写计划这事其实是去年才真的开始的，都是些不起眼的小事，但却无意做成了挺多，明年还要努力，但还是想先写点小事希望都可以都完成。至于更多的还是要看考没考上研，应该会有所不同。最想完成的几件事 练字，考核结果是楷书能写的基本可以看。 python或者是个人blog希望能学习并完成一个 去比较远的地方玩 如果有可能，还要和萌妹纸混熟一点，感觉她很不一样，总是能一下看出来，但后来就不太准了- -，毕业了就很难看到了，但希望以后还有机会。 要为自己找好出路并努力，以后还是想走纯工科的技术路线，但可能会比较难，希望自己可以努力做到 minecraft建设大业向前推进一大步~ 开通了ku希望明年一个月可以看掉至少一本文学类书。依然要坚持看剧和eevblog，习惯没有字幕。专业书的话要看考研结果= = 其他应该要等结果出来再定了。留个坑。希望自己可以慢慢的改变，很多时候，我习惯不是特别好，容易惹别人生气，并没有太多别的原因，不会说话吧，但毫无恶意，只是希望很多时候能够相互坦诚，也希望大度，大方，无私的人可以活得更幸福，这会是个自私的社会，一直也都是，而且生活所迫很多人都会改变，但还是希望能多点理解，多点关心吧，总是套路得人心毕竟不是我喜欢的。应该也是极其厌恶的。个人的努力并不会有结果，而且会成为异类。2016国际国内都不容易，希望2017可以更好。中华民族伟大复兴的中国梦，加油，中国的少年们加油~]]></content>
      <categories>
        <category>计划</category>
      </categories>
      <tags>
        <tag>计划</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2016年计划]]></title>
    <url>%2F2015%2F12%2F31%2F2015-12-31-plan%2F</url>
    <content type="text"><![CDATA[2015年，相对于以往充实了很多，但是真的是习惯了懒惰就很难再勤劳起来。看了14年写的15年要干的真的是好幼稚，过去不堪回首。先讲一下对于15年自己看不惯自己的。 手机仍然使用太频繁，但没有干多少有意义的事，社交网络使用过于频繁。 生活规律间歇性失常。 经常想一些不该想的事情，导致做事的时候发呆不专注 该改的习惯一个没改，还是那么说的比做的多，还是说话，做事不经大脑 字没好好练，名字写出来还是那么烂 c++还是没看完，专业书看的很慢，倒是买书的速度远远比看书的速度快，堆积无数。 图书馆借的书，有的书反复借了多次都没有看过一次 花钱还是太随性，导致额外支出太多 上课还是会开小差，上课效率极差，以至于上课时间浪费，下课还不及时补 布置的任务总是不能按时完成。 以上是15年的十宗罪，写的也许都有些宽泛，毕竟还是赶时间下面谢谢自己在15年做的事 电子设计干的还不错 下半年坚持了每天都看点单词 下半年每周能保证一本书，阅读量增加了不少，看完了三本鬼吹灯，七本明朝那些事，老人与海，dear john，a walk to remember，知乎周刊也看了很多，坚持使用pocket，当然看完了电子电气工程师必知必会也是不容易。 在北京生活了两周，知道了很多东西，了解了很多，生活真的还是要努力。 三级没过，过了四级 终于去了台湾，了解了不一样的风情，好想生活在那么美的城市。 认识了北大的女神，见着了Lizzie（现在都是泪），也看到了妹夫，平安夜还认识了Richia，真的好像和这个萌妹纸混熟了= = 和温温去看了周杰伦的演唱会，了却了人生的梦想。 星巴克半年变成了金星会员，刷遍星巴克有木有。 手机上放弃拼音输入，改成笔画 想想真的也没做什么，微不足道，但是很多真的会让我不会再后悔。我做什么事都是好慢，好能拖，所以才不适合干好多事，总是需要人督促吧。都是泪啊，然而办法是有，但是还是更喜欢自由。 2016年是大学生活里最关键的一年了吧，读研是肯定的，年底就会考试，所以真正属于自己的时间并不多。研究生应该是考的，真的好难。最终要的事情还是要减少手机的使用和多专注于正在做的事情，这样很多事情都能解决。2016年，真的会是人生很关键的一年，15年下半年已经过的很茫然了，我想16年还会更茫然的。经过多日的思考我想2016年要我要完成下面的这些事。先列总的然后再把寒假要做的列上。 减少手机的使用，做事情要专注，减少发朋友圈和看朋友圈的次数，尽量只在早上和晚上睡前什么看看。聊天也是要减少。都要在任务完成的情况下。 坚持看书，坚持看英文原著，坚持看专业书。 学会打五笔，删除拼音输入法 争取实现看剧可以只用英文字幕，减少对中文字幕的依赖 坚持有空就自习。 做好项目，完成梦想。 找到想去的学校，考研和出国，还是会选择考研吧，没底子真的很难啊。 去一个地方玩，远点的 看书 看书多看书才能充实自己啊，其实自己的记忆力很强就是不专注，虽然有点晚了，但是想改变总是不晚的。努力看书吧。多学习。]]></content>
      <categories>
        <category>计划</category>
      </categories>
      <tags>
        <tag>计划</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用分治法计算逆序数]]></title>
    <url>%2F2014%2F10%2F25%2F2014-10-25-divideandconquer%2F</url>
    <content type="text"><![CDATA[也许是第一次写这样的程序，略显生疏，希望通过以后学习能够有更多的进步，因为是在coursera上学算法，全英文课也着实坑爹了点，只能说继续努力吧！！相信自己。我看行！希望有大神可以多提意见，一定认真学习改进。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109/*----------------------------------------------- 名称：Use divide-and-couquer count the inversion 分治法计算逆序数 编写：MISaD 博客：http://blog.csdn.net/misadd 日期：2014.10.25 修改：2014.10.25 主要错误在于1.错误估计了逆序数的大小，先使用了long 2.merge中错误计算了逆序数个数 内容：1.读入文件流 2.子程序1,sorted-and-count，将数组递归分为两部分从而分别计算每一部分的逆序数 。 3.子程序2,merge-and-count,使用归并排序计算两部分组合的逆序数。 ------------------------------------------------*/ #include &lt;iostream&gt; #include &lt;fstream&gt;// 读入文件流 #include &lt;vector&gt;//创建vector数组 using namespace std; long long CountInversion(vector&lt;long long&gt;&amp;vec); long long merge(vector&lt;long long&gt;&amp; vec,vector&lt;long long&gt;&amp; v1,vector&lt;long long&gt;&amp; v2); int main() &#123; ifstream fin("IntegerArray.txt"); vector&lt;long long&gt; init; long long temp; while(fin&gt;&gt;temp)&#123; init.push_back(temp); &#125; long long dataSize = init.size() ; cout&lt;&lt;"Data Size:"&lt;&lt;dataSize&lt;&lt;endl; long long x = CountInversion(init); cout&lt;&lt;x&lt;&lt;endl; return 0; &#125; long long CountInversion(vector&lt;long long&gt;&amp;vec) &#123; long long n = vec.size(); if( 1 == n ) return 0; long long result = 0; long long mid = n/2; vector&lt;long long&gt; v1,v2; long long k = 0; while(k &lt; n)&#123; if(k &lt; mid)&#123; v1.push_back(vec[k]); k++; &#125; else&#123; v2.push_back(vec[k]); k++; &#125; &#125; long long leftNum,rightNum,splitNum; leftNum = CountInversion(v1); rightNum = CountInversion(v2); splitNum = merge(vec,v1,v2); result = leftNum+rightNum+splitNum; return result; &#125; long long merge(vector&lt;long long&gt;&amp; vec,vector&lt;long long&gt;&amp; v1,vector&lt;long long&gt;&amp; v2) &#123; long long n1 = v1.size(); long long n2 = v2.size(); long long n = n1 + n2; long long num = 0;//split-inversion number long long p1 = 0,p2 = 0; long long k = 0; while(k &lt; n &amp;&amp; p1 &lt; n1 &amp;&amp; p2 &lt; n2) &#123; if(v1[p1] &gt; v2[p2])&#123; vec[k] = v2[p2]; num +=n1-p1; p2++; &#125; else&#123; vec[k] =v1[p1]; p1++; &#125; k++; &#125; while(p1 &lt; n1)&#123; vec[k] = v1[p1]; p1++; k++; &#125; while(p2 &lt; n2)&#123; vec[k] = v2[p2]; p2++; k++; &#125; return num; &#125; 首先讲一下基本的原理首先用递归不断的将数组分成v1(0，mid-1)和v2(mid,n)两部分，具体计算逆序数则是通过归并排序来实现的，那么归并排序怎么实现计算逆序数的功能呢？我们不妨假设v1,v2是两个分别已经按从小到达排好序的数组，所以如果v1[p1]&gt;v2[p2],那么v1中所有从p1开始到mid-1的数都可以与v2[p2]这一个元素是逆序组，所以通过归并排序可以省时省力的计算每一部分中的逆序数，最后只要将各部分的逆序数相加，就可以得到最终结果。 具体写程序的时候有一些问题，首先是读入文件流的时候有下面几种方法1234while(fin&gt;&gt;temp) &#123; init.push_back(temp); &#125; 1234for(int p = 0; p &lt; 100000; p++) &#123; fin&gt;&gt;temp; init.push_back(temp); &#125; 但是不能这样1234while(!fin.eof()) &#123; fin&gt;&gt;temp; init.push_back(temp); &#125; 因为fin读到文件末尾的时候，再次进行读写才会发现已经到了文件的末尾无法读取了，因此才会返回true；比如说读到了最后一个数据了，此时仍然为false；当再次读入时候发现不能再读了,这时候才会返回true结束循环，然而这时已经将最后一个数据写入了两次。 然后应用vector数组的优势是比较灵活，push_back（x）的作用是将x依次放入数组；size()作用是表示数组的大小； 两个子函数的作用在思路中已经做了简单的描述再次不想多说，然后我还想说一下数据大小；因为我做的是1-100000中所有的数的任意排序的逆序数，所以是一个超出了2^31次，所以用long是不行的，所以改成了long long；当然也可以用double,但是直接输出的话会输出科学计数法，所以需要用1cout.setf(ios_base::fixed,ios_base::floatfield); 当然还看到有大神是这么用的123char str[20]; sprintf(str,"%.8lf",x);//将格式化后的x存到字符串str中 （将浮点型转换成字符串） printf("%s",str);//不转换会按科学计数法输出 简言之就是讲一个double的数字符串化之后输出。]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>分治</tag>
        <tag>技术</tag>
        <tag>算法</tag>
      </tags>
  </entry>
</search>
